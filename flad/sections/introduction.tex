\section{Introduction}

% Few-shot learning, challenges, and introduction to FLAD.
Few-shot learning is an attractive learning setting for many reasons: it promises efficiency in cost and time, and in some scenarios data is simply not available due to privacy concerns or the nature of the problem. However, few-shot learning is also a challenging setting that requires a delicate balance between learning the structure of the feature and label spaces while preventing overfitting to the limited training samples \citep{ravi2017optimization, 10.1145/3386252, https://doi.org/10.48550/arxiv.2203.04291}. One approach to improving the generalizability of models in the few-shot setting is \textbf{F}ew-shot \textbf{L}earning with \textbf{A}uxiliary \textbf{D}ata (FLAD), where auxiliary data is available that can be used to improve generalization on a target few-shot task \citep{10.1145/1015330.1015436, https://doi.org/10.48550/arxiv.1812.02224, esfandiarpoor2021, Verboven2022}.

 % \begin{figure}[t!]
 %     \centering
 %     \includegraphics[width=0.9\columnwidth]{images/bandit_visualization.pdf}
 %     \caption{A simple demonstration of few-shot learning with auxiliary data as multi-armed bandits. In step 1 a batch is sampled from auxiliary datasets, then in step 2 the model produces a reward. In step 3 the sampling distribution gets updated based on the reward.}
 %     \label{fig:simple_demo}
 % \end{figure}
 \begin{figure*}
     \centering
     \includegraphics[width=\textwidth]{images/flad_overview.pdf}
     \vspace{-5mm}
     \caption{Overview of our formulation of few-shot learning with auxiliary data as a multi-armed bandit problem, as described in Section \ref{sec:mab_to_flad}.}
     \label{fig:flad_overview}
 \end{figure*}

 
% What are the challenges of FLAD?
FLAD methods introduce their own challenges, including algorithmic and computational complexity.
% Algorithmic complexity
Incorporating auxiliary data into the training algorithm introduces a large space of design choices for FLAD learning algorithms (e.g.\ how and when to train on auxiliary data).
Manually designing the curriculum for training on large quantities of auxiliary data is not feasible due to the combinatorially large search space, and hand-picking which auxiliary data to use (e.g.\ in-domain or on-task) may lead to sub-optimal results (see section 6.2 from~\citet{feta_albalak}).
% Computational complexity
Delegating such design choices to an algorithm can lead to better solutions, as demonstrated in the transfer learning \citep{vu-etal-2020-exploring, pruksachatkun-etal-2020-intermediate}, meta-learning \citep{10.5555/296635, bansal-etal-2020-self}, and multi-task literature \citep{Wu2020Understanding, aghajanyan-etal-2021-muppet}. However, such algorithmic design choices require additional computation, motivating the search for efficient methods as the quantity of auxiliary data increases.

% Our FLAD setting and desiderata for a FLAD algorithm
In this work, we consider the FLAD setting where auxiliary data is divided into separate datasets and training occurs simultaneously over both the target and auxiliary datasets. We desire a FLAD algorithm that

% \begin{enumerate}[topsep=0pt,partopsep=0pt,parsep=0pt]
\begin{enumerate}[nosep]
    \item makes no assumptions on available auxiliary data a-priori (in-domain, on-task, quality, quantity, etc.),
    \item continuously updates beliefs on importance of auxiliary data, and
    \item adds minimal memory and computational overhead.
\end{enumerate}

% How do we relate our problem to MAB?
In this work, we design algorithms that satisfy our desiderata by drawing inspiration from the central problem in multi-armed bandits (MAB) settings: the exploration-exploitation trade-off \citep{macready1998bandit, simpkins2008optimal}. We relate the set of auxiliary datasets to the arms of a MAB and tailor the classic \ex{} \citep{auer2002nonstochastic} and \ucb{} \citep{auer2002finite} algorithms to fit the FLAD framework by designing an efficient gradient-based reward signal. Figure \ref{fig:flad_overview} provides a basic illustration of how we formulate FLAD as an MAB problem.

% What does this paper do?
Our study presents two efficient algorithms, \ex{}-FLAD and \ucb{}-FLAD, which enhance the generalization capabilities of a machine learning model. To empirically validate our approaches, we utilize readily available auxiliary datasets from P3 \citep{bach-etal-2022-promptsource} which may be in- or out-of-domain and related or unrelated to the target task. We evaluate our methods on the same held-out tasks as T0~\citep{sanh2022multitask} and show that, when using the same collection of auxiliary datasets, our algorithms outperform T0 (which simply concatenates the constituent datasets of P3) by 5.1\% (\ex{}-FLAD) and 5.6\% (\ucb{}-FLAD) absolute. Furthermore, incorporating all available datasets in P3 (i.e.\ not just those used to train T0) increases the improvement to 7.6\% and 9.1\%.

% Summarization of contributions/findings

In summary, our main contributions are:
\begin{itemize}[nosep]
    \item We connect FLAD to the MAB setting and focus on the exploration-exploitation trade-off.
    \item We design two algorithms, \ex{}-FLAD and \ucb{}-FLAD that adapt existing MAB methods to the FLAD setting and propose a reward function that is simple and efficient (in both space and computational costs). 
    \item We present experimental results that validate that our methods improve few-shot performance of pretrained language models and show that strategies that employ only exploration or exploitation lead to sub-optimal performance.
    \item We perform two case studies to better understand why \ex{}-FLAD and \ucb{}-FLAD outperform baselines.
\end{itemize}